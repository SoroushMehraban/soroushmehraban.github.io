<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Soroush Mehraban</title>

  <meta name="author" content="Soroush Mehraban">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Soroush Mehraban
                  </p>
                  <p>
                    I'm a third-year PhD student at University of Toronto, advised by <a
                      href="https://www.cs.toronto.edu/~taati/">Dr. Babak Taati</a> , and Faculty Affiliate Researcher at
                    <a href="https://vectorinstitute.ai/" class="href">Vector institute</a> . My research focuses on
                    analyzing videos for human motion analysis including 3D human pose estimation, 3D human mesh recovery, action recognition, and gait assessment. I'm currently doing an internship in <a href="https://pickford.ai/" class="href">Pickford AI</a>, focusing on video style transferring.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:soroush.mehraban@mail.utoronto.ca">Email</a> &nbsp;/&nbsp;
                    <a href="data/CV___Soroush_Mehraban.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=u2uPzeEAAAAJ&hl=en&oi=ao">Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://x.com/soroushmhrbn">Twitter</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/soroush-mehraban/">Linkedin</a> &nbsp;/&nbsp;
                    <a href="https://www.youtube.com/@SoroushMehraban">YouTube</a> &nbsp;/&nbsp;
                    <a href="https://github.com/soroushmehraban/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/soroush.jpg"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/soroush.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I'm interested in computer vision, Self-supervised learning, generative models, and their
                    application to a range of problems. Currently I'm focusing on 3D human pose/mesh estimation from
                    monocular videos. Some of my works are mentioned below.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/tpg.jpg" alt="dise">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/TaatiTeam/Token-Perturbation-Guidance">
                    <span class="papertitle">Token Perturbation Guidance for Diffusion Models</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=nJAyYVYAAAAJ&hl=en">Mohammad Javad Rajabi</a>,
                  <strong>Soroush Mehraban</strong>,
                  <a href="https://ait.ethz.ch/people/morteza">Seyedmorteza Sadat</a>,
                  <a href="https://www.cs.toronto.edu/~taati/">Babak Taati</a>
                  <br>
                  <em>arXiv</em>
                  <br>
                  <a href="https://github.com/TaatiTeam/Token-Perturbation-Guidance">GitHub</a>
                  /
                  <a href="https://arxiv.org/abs/2506.10036">arXiv</a>
                  <p></p>
                  <p>
                    A simple yet effective method based on token shuffling for extending the benefits of CFG to broader settings, including unconditional generation.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/lift.png" alt="dise">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://amirhossein-kz.github.io/lift/">
                    <span class="papertitle">LIFT: Latent Implicit Functions for Task- and Data-Agnostic Encoding</span>
                  </a>
                  <br>
                  <a href="https://amirhossein-kz.github.io/">Amirhossein Kazerouni</a>,
                  <strong>Soroush Mehraban</strong>,
                  <a href="https://brudno.uhndata.io/">Michael Brudno</a>,
                  <a href="https://www.cs.toronto.edu/~taati/">Babak Taati</a>
                  <br>
                  <em>ICCV 2025</em>
                  <br>
                  <a href="https://amirhossein-kz.github.io/lift/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2503.15420">arXiv</a>
                  <p></p>
                  <p>
                    LIFT enables unified implicit neural representations across diverse tasks by leveraging localized implicit functions and a hierarchical latent generator.
                  </p>
                </td>
              </tr>
              
              <tr>
                <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <video style="width:100%;max-width:100%" autoplay muted loop playsinline>
                    <source src="videos/gaitgen.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://vadeli.github.io/GAITGen/">
                    <span class="papertitle">GAITGen: Disentangled Motion-Pathology Impaired Gait Generative Model</span>
                  </a>
                  <br>
                  <a href="https://vadeli.github.io/">Vida Adeli</a>,
                  <strong>Soroush Mehraban</strong>,
                  <a href="https://majidmirmehdi.github.io/">Majid Mirmehdi</a>,
                  <a href="https://research-information.bris.ac.uk/en/persons/alan-l-whone">Alan Whone</a>,
                  <a href="https://www.tudelft.nl/en/staff/b.filtjens/">Benjamin Filtjens</a>,
                  <a href="https://research-information.bris.ac.uk/en/persons/amirhossein-dadashzadeh-2">Amirhossein Dadashzadeh</a>,
                  <a href="https://www.uhnresearch.ca/researcher/alfonso-fasano">Alfonso Fasano</a>,
                  <a href="https://psychiatry.utoronto.ca/faculty/andrea-iaboni">Andrea Iaboni</a>,
                  <a href="https://www.cs.toronto.edu/~taati/">Babak Taati</a>
                  <br>
                  <em>arXiv</em>
                  <br>
                  <a href="https://vadeli.github.io/GAITGen/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2503.22397">arXiv</a>
                  <p></p>
                  <p>
                    GAITGen is a generative framework that synthesizes realistic gait sequences conditioned on Parkinsonâ€™s severity. Using a Conditional Residual VQ-VAE and tailored Transformers, it disentangles motion and pathology features to produce clinically meaningful gait data. GAITGen enhances dataset diversity and improves performance in parkinsonian gait analysis tasks.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/stars.jpg" alt="dise">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://soroushmehraban.github.io/stars/">
                    <span class="papertitle">STARS: Self-supervised 3D Action Recognition with Contrastive Tuning</span>
                  </a>
                  <br>
                  <strong>Soroush Mehraban</strong>,
                  <a href="https://scholar.google.com/citations?user=nJAyYVYAAAAJ&hl=en">Mohammad Javad Rajabi</a>,
                  <a href="https://www.cs.toronto.edu/~taati/">Babak Taati</a>
                  <br>
                  <em>arXiv</em>
                  <br>
                  <a href="https://soroushmehraban.github.io/stars/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2407.10935">arXiv</a>
                  <p></p>
                  <p>
                    STARS enhances the Mask Autoencoder (MAE) approach in self-supervised learning by applying
                    contrastive tuning. We also show that MAE approaches fail in few-shot settings and achieve improved
                    performance by using the proposed method.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/pdeval.png" alt="dise">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/TaatiTeam/MotionEncoders_parkinsonism_benchmark">
                    <span class="papertitle">Benchmarking Skeleton-based Motion Encoder Models for Clinical
                      Applications: Estimating Parkinson's Disease Severity in Walking Sequences</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=j_mCCb0AAAAJ&hl=en">Vida Adeli</a>,
                  <strong>Soroush Mehraban</strong>,
                  <a href="https://cvl.tuwien.ac.at/staff/irene-ballester-campos/">Irene Ballester</a>,
                  <a href="https://scholar.google.com/citations?user=NIi-VHAAAAAJ&hl=en">Yasamin Zarghami</a>,
                  <a href="https://scholar.google.ca/citations?user=KxhRl2UAAAAJ&hl=en">Andrea Sabo</a>,
                  <a href="https://www.uhnresearch.ca/researcher/andrea-iaboni">Andrea Iaboni</a>,
                  <a href="https://www.cs.toronto.edu/~taati/">Babak Taati</a>
                  <br>
                  <em>FG</em>, 2024
                  <br>
                  <a href="https://github.com/TaatiTeam/MotionEncoders_parkinsonism_benchmark">Code</a>
                  /
                  <a href="https://arxiv.org/abs/2405.17817">arXiv</a>
                  <p></p>
                  <p>
                    Evaluating recent motion encoders for the task of parkinsonism severity estimation (UPDRS III gait)
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/motionagformer.gif" alt="dise">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/TaatiTeam/MotionAGFormer">
                    <span class="papertitle">MotionAGFormer: Enhancing 3D Pose Estimation with a Transformer-GCNFormer
                      Network</span>
                  </a>
                  <br>
                  <strong>Soroush Mehraban</strong>
                  <a href="https://scholar.google.com/citations?user=j_mCCb0AAAAJ&hl=en">Vida Adeli</a>,
                  <a href="https://www.cs.toronto.edu/~taati/">Babak Taati</a>
                  <br>
                  <em>WACV</em>, 2024
                  <br>
                  <a href="https://github.com/TaatiTeam/MotionAGFormer">Code</a>
                  /
                  <a href="https://www.youtube.com/watch?v=iyLhxPjwBuQ">video</a>
                  /
                  <a href="https://arxiv.org/abs/2310.16288">arXiv</a>
                  <p></p>
                  <p>
                    Estimating 3D locations of 17 main joints from a monocular video.
                  </p>
                </td>
              </tr>


            </tbody>
          </table>



          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    <a href="https://jonbarron.info/">Website Template</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <a href="https://clustrmaps.com/site/1c0gs" title="Visit tracker"><img
              src="//www.clustrmaps.com/map_v2.png?d=waI9en-VNY6J_5tgM5_jSpsAvwqr17x7hIA0RC6qy4k&cl=ffffff" /></a>

        </td>
      </tr>
  </table>
  </td>
  </tr>
  </table>
</body>

</html>